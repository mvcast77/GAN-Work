{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow~=2.6.0\n",
      "  Using cached tensorflow-2.6.5-cp39-cp39-win_amd64.whl (429.2 MB)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (1.6.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (1.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (1.12.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (2.6.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (3.19.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (0.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (2.6.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (1.19.5)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (1.42.0)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (5.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (0.37.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions<3.11,>=3.7 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (3.10.0.2)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (3.1.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (1.1.2)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorflow~=2.6.0) (2.6.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (61.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (0.4.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\music\\anaconda3\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (1.33.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\music\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\music\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\music\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\music\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\music\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\music\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\music\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow~=2.6.0) (3.2.2)\n",
      "Installing collected packages: tensorflow\n",
      "2.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\music\\\\anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\lite\\\\experimental\\\\microfrontend\\\\python\\\\ops\\\\_audio_microfrontend_op.so'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow~=2.6.0\n",
    "# !pip install keras~=2.6.0\n",
    "# !pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.keras.layers import (Dense, \n",
    "                                     BatchNormalization, \n",
    "                                     LeakyReLU, \n",
    "                                     Reshape, \n",
    "                                     Conv2DTranspose,\n",
    "                                     Conv2D,\n",
    "                                     Dropout,\n",
    "                                     Flatten)\n",
    "import time\n",
    "from IPython import display\n",
    "from PIL import Image as PImage\n",
    "%matplotlib inline\n",
    "\n",
    "#plt.imshow(trainImages[1,...])\n",
    "def normalize(layer):\n",
    "    return tf.divide(tf.subtract(layer,tf.reduce_min(layer) ), tf.subtract(tf.reduce_max(layer),tf.reduce_min(layer)))\n",
    "#take random noise as input and a starting shape that has dimensions ((7,14,28), (7,14,28), (128, 256, 512)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "def make_generator_model(): \n",
    "    model = tf.keras.Sequential() \n",
    "    model.add(layers.Dense(256*7*7, use_bias=False, input_shape=(100,))) \n",
    "    model.add(layers.BatchNormalization()) \n",
    "    model.add(layers.LeakyReLU(alpha=0.2)) \n",
    "    model.add(layers.Reshape((7, 7, 256))) \n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=init)) \n",
    "    model.add(layers.BatchNormalization()) \n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=init)) \n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2)) \n",
    "\n",
    "    model.add(layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=init))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2)) \n",
    "\n",
    "    model.add(layers.Conv2D(3, (3, 3), padding='same', use_bias=False, activation='tanh')) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init, input_shape=[56, 56, 3]))\n",
    "    model.add(layers.BatchNormalization()) \n",
    "    model.add(layers.LeakyReLU(alpha=0.2))  #shape(56, 56, 32)\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init))\n",
    "    model.add(layers.BatchNormalization()) \n",
    "    model.add(layers.LeakyReLU(alpha=0.2))   #shape(14, 14, 64)\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init))\n",
    "    model.add(layers.BatchNormalization()) \n",
    "    model.add(layers.LeakyReLU(alpha=0.2))  #shape(7, 7, 128)\n",
    "    \n",
    "    model.add(layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', kernel_initializer=init))\n",
    "    model.add(layers.BatchNormalization()) \n",
    "    model.add(layers.LeakyReLU(alpha=0.2))  #shape(7, 7, 256)\n",
    "    model.add(layers.Dropout(0.3))  #dropout is used to prevent overfitting by setting inputs to 0 at a rate determined by paremeter \n",
    "                                   #while training. While have to test how this function affects performance\n",
    "\n",
    "    model.add(layers.Flatten()) #fits all elements into 1 dimension\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))  #Creates a densely-connected layer of size 1\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "\tix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "\t# retrieve selected images\n",
    "\tX = dataset[ix]\n",
    "\t# generate 'real' class labels (1)\n",
    "\ty = np.ones((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate n fake samples with class labels\n",
    "#def generate_fake_samples(n_samples):\n",
    "\t# generate uniform random numbers in [0,1]\n",
    "#\tX = np.random.rand(224 * 224 * 3 * n_samples)\n",
    "\t# reshape into a batch of color images\n",
    "#\tX = X.reshape((n_samples, 224, 224, 3))\n",
    "\t# generate 'fake' class labels (0)\n",
    "#\ty = np.zeros((n_samples, 1))\n",
    "#\treturn X, y\n",
    "\n",
    "#def generate_fake_samples(n_samples):\n",
    "#\tgenerator = make_generator_model()\n",
    "#\tnoise = tf.random.normal([n_samples, 100]) #replace 1 with batch size\n",
    "#\tgenerated_image = generator(noise, training=False)\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "\t# generate points in latent space\n",
    "\tx_input = np.random.randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\t# predict outputs\n",
    "\tX = g_model.predict(x_input)\n",
    "\t# create 'fake' class labels (0)\n",
    "\ty = np.zeros((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\td_model.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = tf.keras.Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(g_model)\n",
    "\t# add the discriminator\n",
    "\tmodel.add(d_model)\n",
    "\t# compile model\n",
    "\topt = tf.keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\treturn model\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = np.random.randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=20000, n_batch=155):\n",
    "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "\tprint(bat_per_epo)\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_epochs):\n",
    "\t\t# enumerate batches over the training set\n",
    "\t\tfor j in range(bat_per_epo):\n",
    "\t\t\t# get randomly selected 'real' samples\n",
    "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\t\t# update discriminator model weights\n",
    "\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
    "\t\t\t# generate 'fake' examples\n",
    "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\t\t\t#plt.imshow((X_fake[0]+1)/2)\n",
    "\t\t\t# update discriminator model weights\n",
    "\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
    "\t\t\t# prepare points in latent space as input for the generator\n",
    "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
    "\t\t\t# create inverted labels for the fake samples\n",
    "\t\t\ty_gan = np.ones((n_batch, 1))\n",
    "\t\t\t# update the generator via the discriminator's error\n",
    "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\t\t\t# summarize loss on this batch\n",
    "\t\t\tprint('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
    "\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.layers' has no attribute 'BatchNormalization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\music\\OneDrive\\Documents\\COEN 140\\Project\\Code\\GAN-Work\\GeneratorTester.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/music/OneDrive/Documents/COEN%20140/Project/Code/GAN-Work/GeneratorTester.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m temp_discrim \u001b[39m=\u001b[39m make_discriminator_model() \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/music/OneDrive/Documents/COEN%20140/Project/Code/GAN-Work/GeneratorTester.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m generator \u001b[39m=\u001b[39m make_generator_model() \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/music/OneDrive/Documents/COEN%20140/Project/Code/GAN-Work/GeneratorTester.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tempImages \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m2\u001b[39m,\u001b[39m56\u001b[39m,\u001b[39m56\u001b[39m,\u001b[39m3\u001b[39m))\n",
      "\u001b[1;32mc:\\Users\\music\\OneDrive\\Documents\\COEN 140\\Project\\Code\\GAN-Work\\GeneratorTester.ipynb Cell 8\u001b[0m in \u001b[0;36mmake_discriminator_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/music/OneDrive/Documents/COEN%20140/Project/Code/GAN-Work/GeneratorTester.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/music/OneDrive/Documents/COEN%20140/Project/Code/GAN-Work/GeneratorTester.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mConv2D(\u001b[39m32\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m, kernel_initializer\u001b[39m=\u001b[39minit, input_shape\u001b[39m=\u001b[39m[\u001b[39m56\u001b[39m, \u001b[39m56\u001b[39m, \u001b[39m3\u001b[39m]))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/music/OneDrive/Documents/COEN%20140/Project/Code/GAN-Work/GeneratorTester.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39;49mBatchNormalization()) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/music/OneDrive/Documents/COEN%20140/Project/Code/GAN-Work/GeneratorTester.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mLeakyReLU(alpha\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m))  \u001b[39m#shape(56, 56, 32)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/music/OneDrive/Documents/COEN%20140/Project/Code/GAN-Work/GeneratorTester.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mConv2D(\u001b[39m64\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m, kernel_initializer\u001b[39m=\u001b[39minit))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.layers' has no attribute 'BatchNormalization'"
     ]
    }
   ],
   "source": [
    "temp_discrim = make_discriminator_model() \n",
    "generator = make_generator_model() \n",
    "tempImages = np.zeros((2,56,56,3))\n",
    "gan_model = define_gan(generator, temp_discrim)\n",
    "#need to initialize weights of generator so create temporary GAN and train once to initialize\n",
    "train(generator, temp_discrim, gan_model, tempImages, 100, n_epochs=1, n_batch=2)\n",
    "#Loading the weights from file overwrites temporary weights but has identical model arcitecture\n",
    "generator.load_weights('30minGAN.h5')    \n",
    "while(1):\n",
    "  condition = input(\"Generate New Image? (Y/N): \\n\")\n",
    "  condition.lower()\n",
    "  if(condition == 'y' or condition == 'yes'):\n",
    "    for i in range(0,10):\n",
    "        noise = tf.random.normal([1, 100])                      #Generating new random noise to input into generator\n",
    "        generated_image = generator.predict(noise)         #Sending in Input to Generator, Recieving Image\n",
    "        generated_image = (generated_image+1)/2       #scale from 0 to 1\n",
    "        plt.figure(figsize=(6,6))                             #Plotting the Image\n",
    "        #print(generated_image[0, :, :, :].shape)                #check that image has scaled to correct size\n",
    "        plt.imshow(generated_image[0, :, :, :])\n",
    "        plt.show()\n",
    "\n",
    "  else: break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17833bac77599a4930b019fc8dc29677c5fa429ab6e4a3619dd8f3520b27f227"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
